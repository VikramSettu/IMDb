{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VJogbYYZBWSB9GhEYA7_4BegPNbgkLNB","timestamp":1698296535602}],"authorship_tag":"ABX9TyP7fN016QlK3eL+Q97aHcZY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**IMDb Score Prediction Project **"],"metadata":{"id":"Spp5SzIdUaSq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XX586AdUSWV"},"outputs":[],"source":["# IMDb Score Prediction Project Documentation\n","\n","## Project Overview\n","\n","This documentation provides a detailed overview of the IMDb score prediction project. The project's primary goal is to build a machine learning model that predicts IMDb scores for a dataset of Netflix original titles. IMDb scores are a measure of the perceived quality of a movie or TV show, and this project aims to create a model that can make accurate predictions based on various features.\n","\n","## Project Components\n","\n","The project comprises several key components:\n","\n","### 1. Importing Libraries\n","\n","In the initial part of the code, we import essential Python libraries that are used throughout the project. These libraries include Pandas for data manipulation, NumPy for numerical operations, Matplotlib for data visualization, and scikit-learn for machine learning tasks.\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n"]},{"cell_type":"markdown","source":["** Loading the Dataset**\n","\n","The project begins with loading the dataset from a CSV file named 'NetflixOriginals.csv.' To ensure compatibility with different character encodings, the code attempts various encodings (e.g., 'utf-8,' 'ISO-8859-1,' 'latin1,' 'cp1252') until it successfully loads the data."],"metadata":{"id":"j7CUAHFsVI09"}},{"cell_type":"code","source":["# Load the dataset\n","encodings_to_try = ['utf-8', 'ISO-8859-1', 'latin1', 'cp1252']\n","for encoding in encodings_to_try:\n","    try:\n","        data = pd.read_csv('NetflixOriginals.csv', encoding=encoding)\n","        break\n","    except UnicodeDecodeError:\n","        continue"],"metadata":{"id":"7mHxzpvHVO7p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Feature Engineering**\n","\n","**Text Data Handling (Title Column)**\n","\n","The 'Title' column contains text data representing the titles of Netflix original content. We use the TF-IDF (Term Frequency-Inverse Document Frequency) vectorization technique to transform the text data into numerical features. The resulting features represent the importance of words in each title.\n","\n"],"metadata":{"id":"afriS9gsVR4h"}},{"cell_type":"code","source":["# Text data handling (Title column)\n","tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n","description_features = tfidf_vectorizer.fit_transform(data['Title']).toarray()"],"metadata":{"id":"0W6o6YMcVf-d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Categorical Variables (Genre and Language Columns)**\n","\n","The 'Genre' and 'Language' columns are categorical in nature. To make them suitable for machine learning, we apply one-hot encoding to convert these categorical variables into a binary format. This process allows the model to consider the impact of each category."],"metadata":{"id":"TR3_MuS_VhXD"}},{"cell_type":"code","source":["# One-hot encode categorical variables (Genre and Language columns)\n","categorical_features = data[['Genre', 'Language']]\n","column_transformer = ColumnTransformer(\n","    transformers=[('cat', OneHotEncoder(), ['Genre', 'Language'])],\n","    remainder='passthrough'\n",")\n","categorical_features = column_transformer.fit_transform(categorical_features)"],"metadata":{"id":"e9o8Aj5gVm5X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Date Features (Premiere Column)**\n","\n","The 'Premiere' column contains dates when the content was premiered on Netflix. We extract features such as the premiere year to incorporate temporal information into the model."],"metadata":{"id":"mx2HdZQuVrc-"}},{"cell_type":"code","source":["# Date Features (Premiere column)\n","data['Premiere'] = pd.to_datetime(data['Premiere'])\n","data['PremiereYear'] = data['Premiere'].dt.year"],"metadata":{"id":"CZoyDbQwVu8v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Feature Scaling**\n","\n","Before training the machine learning model, we standardize the numerical features to ensure that they all have a consistent scale. Standardization helps the model converge more quickly and prevents features with larger values from dominating the training process."],"metadata":{"id":"vE3rOqtDVxZP"}},{"cell_type":"code","source":["# Feature scaling\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"],"metadata":{"id":"dwv0qeNHV2yT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" **Model Training**\n","\n","The core of the project involves training a machine learning model to predict IMDb scores. We use a Linear Regression model, which is a simple yet effective choice for regression tasks.\n","\n","**Splitting the Data**\n","\n","To assess the model's performance accurately, we divide the dataset into training and testing sets using the train_test_split function. This process ensures that the model's performance is evaluated on unseen data."],"metadata":{"id":"H9MPcXngV5cu"}},{"cell_type":"code","source":["# Splitting the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"h8sbDGGGWDcw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hyperparameter Tuning**\n","\n","The model training step may include hyperparameter tuning to optimize the model's performance. Adjustments can be made to hyperparameters, such as the learning rate or regularization strength, as needed."],"metadata":{"id":"YpaojFbiWGvr"}},{"cell_type":"code","source":["# Hyperparameter Tuning\n","model = LinearRegression()\n","model.fit(X_train, y_train)"],"metadata":{"id":"OrlCJWkqWJIy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" **Model Evaluation**\n","\n","**Predict IMDb Scores**\n","\n","Once the model is trained, we use it to make predictions on the test dataset. The predicted IMDb scores are compared to the actual IMDb scores to assess the model's accuracy."],"metadata":{"id":"sQk1Ji3SWK7q"}},{"cell_type":"code","source":["# Model Evaluation\n","y_pred = model.predict(X_test)"],"metadata":{"id":"BO8rGwcnWUz4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Evaluation Metrics**\n","\n","We calculate several evaluation metrics, including:\n","\n","Mean Absolute Error (MAE): Measures the average absolute difference between predicted and actual IMDb scores.\n","Mean Squared Error (MSE): Measures the average squared difference between predicted and actual IMDb scores.\n","Root Mean Squared Error (RMSE): Represents the square root of the MSE and provides a more interpretable measure of error.\n","R-squared (RÂ²): Indicates the proportion of variance in the target variable explained by the model."],"metadata":{"id":"QXE3ExXeWYQ1"}},{"cell_type":"code","source":["# Evaluation Metrics\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(\"Mean Absolute Error:\", mae)\n","print(\"Mean Squared Error:\", mse)\n","print(\"Root Mean Squared Error:\", rmse)\n","print(\"R-squared:\", r2)"],"metadata":{"id":"-BlK-hciWdqD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Cross-Validation**\n","\n","To obtain a more robust estimate of the model's performance, we may perform cross-validation. Cross-validation splits the data into multiple subsets and evaluates the model's performance across different combinations of training and testing sets.\n","\n","**Visualization**\n","\n","To gain insights into the model's predictions, we create a histogram that visualizes the distribution of predicted IMDb scores. This histogram provides a graphical representation of how well the model's predictions align with the actual IMDb scores."],"metadata":{"id":"d3voDY47WhbF"}},{"cell_type":"code","source":["# Visualization\n","plt.hist(y_pred, bins=20)\n","plt.xlabel('Predicted IMDb Score')\n","plt.ylabel('Frequency')\n","plt.title('Predicted IMDb Score Distribution')\n","plt.show()"],"metadata":{"id":"Ujmll6U2Wr9t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Dependencies**\n","\n","The project relies on the following Python libraries:\n","\n","pandas: For data manipulation and analysis.\n","numpy: For numerical operations.\n","matplotlib: For data visualization.\n","scikit-learn: For machine learning tasks, including model training and evaluation."],"metadata":{"id":"g1y5QQWhWv-z"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline"],"metadata":{"id":"4G_Ua0ONW1La"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Usage**\n","\n","To use this project, follow these steps:\n","\n","1.Ensure that you have a CSV file named 'NetflixOriginals.csv' containing the dataset with columns 'Title,' 'Genre,' 'Language,' 'Premiere,' 'Runtime,' and 'IMDB Score.'\n","\n","2.Execute the provided code to preprocess the data, train a model, and evaluate IMDb score predictions.\n","\n","3.You can adjust hyperparameters, modify feature engineering, or experiment with different models to improve prediction accuracy."],"metadata":{"id":"06uMLDxtW2lE"}}]}